---
title: "Curation of ISCN4"
author: "Kathe Todd-Brown"
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
    code-summary: "Show the code"
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
---

Soil carbon stocks are critical components of the land carbon balance.
In a Earth system model context digital soil maps are often used to benchmark and/or parameterize models that simulate the Earth climate over the next 100 years.
Underlying these digital soil maps are large soil survey databases with geo-located soil organic carbon area-densities, further derived from layer-resolved soil carbon volumentric-density profiles.

We have focused on harmonizing two major US soil surveys: USDA-FS-FIA Database (site: 6 071, layers: 23 155), and the USDA-NRCS-NCSS Web of Soil Database (site:115 611, layers:465 897).
We developed meta-data annotations to describe the relevant location, observation time, organic carbon fraction, coarse fraction, and bulk density observations.
These meta-data annotations are then combined with data downloaded from public web-servers and this information used to generate a harmonized data base.
In addition to these two large survey data collections we also harmonize the ISCN3 data collection (site: 10 312, layer: 54 190).
This process is documented here.

A brief word of warning, the size of these databases can be considerable for some computers (<10 GBs).
This code is designed to be run locally on a machine that has the capasity to download and work with this file size.
If your computer is primarily scoped for working with text documents and a few spreadsheets, you may not be able to run this code.
This code uses the `tidyverse` and `RSQLite` packages with additional formating support from `knitr` and `kableExtra`.


```{r setup, message=FALSE, warning=FALSE}
#| code-summary: "Setup"

library(tidyverse) #data structure manipulation
library(RSQLite) #accessing the NCSS sql library
library(knitr) # make prettier tables
library(kableExtra) #make tables scroll-able
library(maps) #make global maps

RscriptsDir <- '../../R'
annotationsDir <- '../../data'
dataDownloadDir <- '../../temp'

#Note that if these change you should also go down and update the appedix read chunks
databaseReads <- list(FIA = 'readFIA.R',
                      ISCN3 = 'readISCN3.R',
                      NCSS = 'readNCSS.R')

annotationFiles <- list(FIA = 'FIA_Annotations.csv',
                        ISCN3 = 'ISCN3Annotations.csv',
                        NCSS = 'NCSS_Annotations.csv')

source(file.path(RscriptsDir, databaseReads$ISCN3))
source(file.path(RscriptsDir, databaseReads$FIA))
source(file.path(RscriptsDir, databaseReads$NCSS))

#knitr::opts_chunk$set(collapse = TRUE)
```

```{r echo=FALSE}
#Set this to any alternative download directory
dataDownloadDir <- '~/Dropbox (UFL)/Research/Datasets'
```

# Data sources

Map the source table and variables to common ones for common ones with ISCN4.
We also include an action note but right now these are not tied directly to code.

```{r}

ISCN4map <- tribble(~study_id, ~table_id, ~source_variable, ~target_variable, ~target_method, ~action_note,
        'ISCN3', 'layer', 'latitude', 'latitude', NA, 'track datum',
        'ISCN3', 'layer', 'longitude', 'longitude', NA, 'track datum',
        'ISCN3', 'layer', 'state', 'state', NA, 'check overlap state names',
        'ISCN3', 'layer','country', 'country', NA, 'rename United States for identified states',
        'ISCN3', 'layer', 'layer_observation_time', 'observation_year', NA, 'Correct for Excel format',
        'ISCN3', 'layer', 'upper_depth_bound', 'upper_depth_bound', NA, 'no transformation needed. known issue with ~100 layers having non-unique ids', 
        'ISCN3', 'layer', 'lower_depth_bound', 'lower_depth_bound', NA, 'no transformation needed. known issue with ~100 layers having non-unique ids',
        'ISCN3', 'layer', "bulk_density_other", 'bulk_density_unknown', 'unknown', 'no transformation needed',
        'ISCN3', 'layer', "bulk_density_sample", 'bulk_density_fine', 'measured', 'no transformation needed',
        'ISCN3', 'layer', "bulk_density_total", 'bulk_density_whole', 'measured', 'no transformation needed',
        'ISCN3', 'layer', "bulk_density_whole", 'bulk_density_whole', 'estimated', 'no transformation needed',
        'ISCN3', 'layer', 'organic_carbon', 'organic_carbon', NA, 'no transformation needed',
        'ISCN3', 'layer', 'organic_matter', 'loss_on_ignition', NA, 'no transformation needed',
        'ISCN3', 'layer', 'total_carbon', 'total_carbon', NA, 'no transformation needed',
        'ISCN3', 'layer', 'calcium_carbonate', 'inorganic_carbon', NA, 'no transformation needed',
        'ISCN3', 'layer', 'coarse_fragment', 'coarse_fraction', NA, 'no transformation needed',
        'FIA', 'ENTIRE_SOILS_LAB', 'Inventory_year', 'observation_year', NA, 'Correct for Excel format',
        'FIA', 'ENTIRE_PLOT', 'State', 'state', NA, 'check overlap state names',
        'FIA', 'ENTIRE_PLOT', 'Longtitude', 'longitude', NA, 'track datum, Pacific Islands non-standard',
        'FIA', 'ENTIRE_PLOT', 'Latitude', 'latitude', NA, 'track datum, Pacific Islands non-standard',
        'FIA', 'ENTIRE_SOILS_LAB', 'Layer_type', 'upper_depth_bound', NA, 'pull control vocabulary and convert inches to cm',
        'FIA', 'ENTIRE_SOILS_LAB', 'Layer_type', 'lower_depth_bound', NA, 'pull control vocabulary and convert inches to cm',
        'FIA', 'ENTIRE_SOILS_LAB', 'Bulk_density', 'bulk_density_whole', 'measured', 'no transformation needed',
        'FIA', 'ENTIRE_SOILS_LAB', 'coarse_fraction', 'coarse_fraction', NA, 'no transformation needed',
        'FIA', 'ENTIRE_SOILS_LAB', 'organic_carbon', 'organic_carbon', NA, 'no transformation needed',
        'FIA', 'ENTIRE_SOILS_LAB', 'inorganic_carbon', 'inorganic_carbon', NA, 'no transformation needed',
        'FIA', 'ENTIRE_SOILS_LAB', 'carbon_fraction', 'carbon_fraction', NA, 'no transformation needed',
        'FIA', 'ENTIRE_SOILS_SAMPLE_LOC', 'Forest_floor_depth_avg', 'depth_to_mineral', NA, 'convert units to cm from tenths of inches',
        'FIA', 'ENTIRE_SOILS_SAMPLE_LOC', 'Litter_layer_depth_avg', 'depth_litter', NA, 'convert units to cm from tenths of inches',
        #'NCSS', NA, 'analysis_procedure', , NA, ,
        #'NCSS', NA, 'NA', , NA, ,
        #'NCSS', NA, 'region', , NA, ,
        'NCSS', NA, 'whole_soil_bulk_density', 'bulk_density_whole', NA, NA,
        'NCSS', NA, 'coarse_fraction', 'coarse_fraction', NA, NA,
        'NCSS', NA, 'total_carbon', 'total_carbon', NA, NA,
        'NCSS', NA, 'organic_carbon_estimated', 'organic_carbon', 'estimated', NA,
        'NCSS', NA, 'organic_carbon_walkley_black', 'organic_carbon', 'measured:walkley_black', NA,
        'NCSS', NA, 'layer_bottom', 'lower_depth_bound', NA, NA ,
        #'NCSS', NA, 'horizon_designation', , NA, ,
        #'NCSS', NA, 'horizon_designation_other', , NA, ,
        'NCSS', NA, 'layer_top', 'upper_depth_bound', NA, NA,
        #'NCSS', NA, 'layer_order', , NA, ,
        'NCSS', NA, 'layer_type', 'depth_bound_defined' , NA, NA,
        'NCSS', NA, 'observation_date','observation_year', NA, 'Correct for Excel format',
        #'NCSS', NA, 'sample_preparation', , NA, ,
        'NCSS', NA, 'mineral_remaining_on_ignition', 'loss_on_ignition', NA, NA,
        'NCSS', NA, 'longitude', 'longitude', NA, NA,
        'NCSS', NA, 'latitude', 'latitude', NA, NA)

ISCN4map |>
  knitr::kable() |>
  kable_paper() |>
  scroll_box(width = "100%", height = "300px")
```

```{r}

#list of primary data objects to carry forward
primary_variables <- c(ls() , 'primary_variables')

```

## ISCN3

The International Soil Carbon Network (vs3) Data base is a collection of single studies and an earlier version of the NCSS database.
In this workflow we use the `readISCN3` function ready in the version of ISCN3 [archived on EDI](https://portal.edirepository.org/nis/mapbrowse?scope=edi&identifier=1160&revision=1).
We then remove the NRCS NCSS database (vs 2015) so that we can later replace it with our updated version (vs 2024 - Web of Science).
Finally we subset the observed variables to focus on soil oraganic carbon measurements.

```{r readISCN3}
#| code-fold: false

ISCN_lvl0.ls <- readISCN3(dataDir = file.path(dataDownloadDir, '/ISCN3'),
                     annotationFilename = file.path(annotationsDir, annotationFiles$ISCN3),
                     format = 'long',
                     verbose = FALSE)

```


```{r}
#| code-summary: "ID columns"

#Use the annotations to set up the column selection
#Pulled up here for ease of reference/review
ISCN3_column_selection <- ISCN_lvl0.ls$annotation |>
  semi_join(ISCN4map,
            by = join_by(study_id, table_id,
                         of_variable == source_variable)) |>
  filter(with_entry == '--') |>
  select(ends_with('_id'), of_variable, is_type)

ISCN3_column_selection |>
  knitr::kable() |>
  kable_paper() |>
  scroll_box(width = "100%", height = "300px")
```

```{r}
#| code-summary: "Subset ISCN3 lvl 1 product"


ISCN3_lvl1 <- list(
  primary = ISCN_lvl0.ls$long |> 
    ##nrow 17 967 513
    filter(!str_detect(dataset_id, 'NRCS')) |> #remove the old NCSS data, using update later in code
    ##nrow  2 151 476
    # use the column selection to subset the database
    inner_join(ISCN_lvl0.ls$annotation |>
                 #pull the annotations for the primary data entries
                 right_join(ISCN4map,
                           by = join_by(study_id, table_id,
                                        of_variable == source_variable)) |>
                 filter(with_entry == '--') |>
                 select(ends_with('_id'), of_variable, target_variable, is_type), 
               relationship = "many-to-many",
               by = join_by(table_id, column_id)) |>
    select(table_id, column_id, study_id, dataset_id, profile_id, layer_id, 
           #remove the soc identifier since we are not pulling calculated SOC
           of_variable, target_variable, is_type, with_entry) |>
    #nrow 1034386
    #TODO: Worldwide soil carbon and Northern Circumpolar needs to be address in readISCN
    #.... removing them for now
    filter(length(with_entry) == 1 | unique(is_type) != 'value',
           .by = -with_entry) |>
    #nrow 931464
    ### Pull the column id into a non-value with_entry and collapse
    ### This takes care of observations with multiple methods
    mutate(with_entry = if_else(is_type != 'value', 
                                paste(column_id, with_entry, sep = ':'), 
                                with_entry)) |>
   #### Remove duplicate observations from ISCN3 ####
   unique() |> #some entries repeated due to soc_id replication of non SOC variables
   #### Kick out to wide format for QAQC ####
    select(study_id, study_id, dataset_id, profile_id, layer_id,, #_id are the row identifier
           target_variable, is_type, with_entry) |>
    pivot_wider(names_from = c(target_variable, is_type), names_sep = '::',
              values_from = with_entry, values_fn = function(xx)paste(xx, collapse = ';\n')), 
  
  #pull in the meta data that is not now in the primary data
  meta = ISCN_lvl0.ls$annotation |>
    inner_join(ISCN4map |>
                 filter(study_id == 'ISCN3'),
               by = join_by(study_id, table_id,
                            of_variable == source_variable)) |>
    filter(with_entry != '--') |>
    mutate(with_entry = if_else(is_type != 'value', 
                                paste(column_id, with_entry, sep = ':'), 
                                with_entry)) |>
    mutate(column_id = paste0(target_variable, is_type, sep = '::')) |>
    select(study_id, column_id, with_entry, method_class = target_method, action_note)
)

#memory management
primary_variables <- c(primary_variables, 'ISCN_lvl0.ls',  'ISCN3_lvl1')
rm(list = setdiff(ls(), primary_variables)) 
```


## Forest Inventory Analysis Database (USDA-FS)

The Forest Inventory Analysis Database from the USDA-FS focuses primarily on tree survey data however it does contain soil information for two layers from 0-4 inches and 4-8 inches as well as litter information.
This data set is large and must be downloaded from [the FIA Datamart](https://www.fs.usda.gov/research/products/dataandtools/tools/fia-datamart).
We then run the `readFIA` function to combine the datatables into a single long format and down select to focus on soil organic carbon stocks.

```{r}
#| code-fold: false

FIA_lvl0.ls <- readFIA(file.path(dataDownloadDir, 'FS_FIA'), 
                  annotationFilename = file.path(annotationsDir, annotationFiles$FIA), 
                  verbose = FALSE, #when first running, switch this to true 
                  format = 'long')
#The FIA data base object is large, 2.3 GB
```

```{r}

FIA_controlVocab <- FIA_lvl0.ls$annotations |>
  filter(is_type == 'control_vocabulary') |>
  tidyr::separate_longer_delim(with_entry, delim = ';') |>
  filter(str_detect(with_entry, regex('\\|'))) |>
  tidyr::separate_wider_delim(with_entry, delim = '|', 
                              names = c('with_entry', 'keyed_value')) %>%
  mutate(is_type = 'value')

FIA_lvl1 <- list(
  primary =  FIA_lvl0.ls$long |>
    #### pull in the target variable that we want to map ####
    right_join(FIA_lvl0.ls$annotation |>
                 #pull the annotations for the primary data entries
                 right_join(ISCN4map,
                            by = join_by(study_id, table_id,
                                         of_variable == source_variable),
                            relationship = "many-to-many") |>
                 filter(with_entry == '--') |>
                 select(ends_with('_id'), of_variable, target_variable, is_type),
               relationship = "many-to-many",
               by = join_by(column_id, table_id)) |>
    #### replace the control vocab with the provided text values ####
    left_join(FIA_controlVocab,
              by = join_by(study_id, table_id, column_id, 
                           of_variable, is_type, with_entry)) |>
    mutate(with_entry = if_else(is.na(keyed_value), with_entry, keyed_value)) |>
    select(-keyed_value) |>
    #### Kick out to wide format for QAQC ####
    select(study_id, 
           profile_id = `CN.ENTIRE_PLOT`,
           layer_id = `CN.ENTIRE_SOILS_LAB`, #starts_with('CN.'), #CN is the row identifier
           target_variable, is_type, with_entry) |>
  unique() |>
  pivot_wider(names_from = c(target_variable, is_type), names_sep = '::',
                values_from = with_entry,
                values_fn = function(xx)paste(xx, collapse = '::')),
  
  meta = FIA_lvl0.ls$annotations |>
    #pull the annotations for the primary data entries
    right_join(ISCN4map,
               by = join_by(study_id, table_id,
                            of_variable == source_variable),
               relationship = "many-to-many")  |>
    filter(is_type != 'control_vocabulary') |>
    filter(with_entry != '--') |>
    mutate(with_entry = if_else(is_type != 'value', 
                                paste(column_id, with_entry, sep = ':'), 
                                with_entry)) |>
    #### Construct the column names ####
    mutate(column_id = paste0(target_variable, "::", is_type)) |>
    select(study_id, column_id, 
           with_entry, method_class = target_method, action_note)
    
)

#memory management
primary_variables <- c(primary_variables, 'FIA_lvl0.ls', 'FIA_lvl1')
rm(list = setdiff(ls(), primary_variables)) 
```

## NCSS (USDA-NRCS, Web of Soil version)

The National Cooperative Soil Survey (USDA-NRCS) holds 

```{r warning=FALSE}
#| code-fold: false

NCSS_lvl0.ls <- readNCSS(dataDir = file.path(dataDownloadDir, 'NRCS_NCSS_20230922'),
                    annotationFilename = file.path(annotationsDir, 'NCSS_Annotations.csv'),
                   format = 'long',
                   verbose = FALSE)
```

```{r}
#| code-summary: "Subset NCSS lvl 1 product"

NCSS_lvl1 <- list(
  primary =  NCSS_lvl0.ls$long |> 
    mutate(study_id = 'NCSS', 
           profile_id = paste0('site_key:', site_key,
                               '-pedon_key:', pedon_key)) |>
    select(study_id, profile_id, layer_id = layer_key, #row ids
           table_id, column_id, #original-variable ids
           of_variable, is_type, with_entry) |> #meta information
    ##nrow 5 694 780
    # use the column selection to subset the database
    inner_join(NCSS_lvl0.ls$annotation |>
                 mutate(study_id = 'NCSS') |>
                 select(study_id, table_id, column_id, of_variable, is_type, with_entry) |>
                 filter(with_entry == '--') |>
                 #pull the annotations for the primary data entries
                 right_join(ISCN4map,
                            by = join_by(study_id,#table_id, column_id #not annotated for NCSS
                                         of_variable == source_variable))  |>
                 select(ends_with('_id'), of_variable, target_variable, is_type), 
               relationship = "many-to-many",
               by = join_by(study_id, column_id, of_variable, is_type)) |>
    select(study_id, column_id, profile_id, layer_id, 
           of_variable, target_variable, is_type, with_entry) |>
    #nrow 3 754 657
    ### Pull the column id into a non-value with_entry and collapse
    ### This takes care of observations with multiple methods
    mutate(with_entry = if_else(is_type != 'value', 
                                paste(column_id, with_entry, sep = ':'), 
                                with_entry)) |>
    #### Kick out to wide format for QAQC ####
  select(study_id, profile_id, layer_id,
         target_variable, is_type, with_entry) |>
    pivot_wider(names_from = c(target_variable, is_type), names_sep = '::',
                values_from = with_entry, values_fn = function(xx)paste(xx, collapse = ';\n')), 
  
  #pull in the meta data that is not now in the primary data
  meta = NCSS_lvl0.ls$annotation |>
    mutate(study_id = 'NCSS') |>
    inner_join(ISCN4map |>
                 filter(study_id == 'NCSS'),
               by = join_by(study_id, #table_id
                            of_variable == source_variable)) |>
    filter(with_entry != '--') |>
    mutate(with_entry = if_else(is_type != 'value', 
                                paste(column_id, with_entry, sep = ':'), 
                                with_entry)) |>
    mutate(column_id = paste0(target_variable, is_type, sep = '::')) |>
    select(study_id, column_id, with_entry, method_class = target_method, action_note)
)

#memory management
primary_variables <- c(primary_variables, 'NCSS_lvl0.ls', 'NCSS_lvl1')
rm(list = setdiff(ls(), primary_variables)) 
```

# Harmonize sources


Examining the contextual metadata above we need to do the following:

  + country and state
    * FIA: Extract the control vocabulary and substitute it into those entries
    * All: Ensure consistent state and country names (capitalization and convention)
  + latitude and longitude
    * All: Check for upper/lower bounds (latitude -180:180, longitude -90:90)
    * All: populate datum for each value or label as unknown
  + layer depth
    * FIA: populate upper and lower bounds from control vocabulary
    * All: check zero location
    * FIA: convert to units to cm
  + observation year
    * ISCN3: convert from days since origin (unless under 2100)
  + bulk density
    * ISCN3: remove known fine earth bulk density
    * All: convert units to g cm-3
    * All: move over method notes to primary data
  + organic carbon, inorganic carbon, and coarse fraction
    * All: convert units to mass-percent
    * All: move over method notes to primary data

```{r}

ISCN4_primary <- ISCN3_lvl1$primary |>
  bind_rows(
  FIA_lvl1$primary |>
    # mutate(profile_id = paste('PLOT:', `CN.ENTIRE_PLOT`),
    #        layer_id = paste('SOILS_VISIT:',`CN.ENTIRE_SOILS_VISIT`, 
    #                         '-SOILS_SAMPLE_LOC:', `CN.ENTIRE_SOILS_SAMPLE_LOC`,
    #                         '-SOILS_EROSION:', `CN.ENTIRE_SOILS_EROSION`,
    #                         '-SOILS_LAB:', `CN.ENTIRE_SOILS_LAB`, sep = '')) |>
    mutate(`depth_bound::method` = `upper_depth_bound::value`) |>
    select(-c(`upper_depth_bound::value`, `lower_depth_bound::value`)) |>
    mutate(`latitude::method` = 'NAD83') #This applies for non Pacific Island locations, Pacific Island locations are WSG84, no current PI locations - 20240625 KTB
  ) |>
  bind_rows(NCSS_lvl1$primary) |>
  # country/state
  rename(state = `state::value`, country = `country::value`) |>
  mutate(country = if_else(country == 'Unknown', NA_character_, country),
         state = if_else(state == 'Unknown', NA_character_, state)) |>
  # if there is a state defined, then the country is in the US
  mutate(country = if_else(is.na(country) & !is.na(state), 'United States', country)) |>
  # latitude/longitude/datum
  rename(latitude = `latitude::value`, 
         longitude = `longitude::value`, 
         datum = `latitude::method`) |>
  mutate(datum = str_remove(datum, pattern = regex('.*\\:')) )|>
  mutate(across(c(latitude, longitude), as.numeric)) |>
  # layer depth
  rename(upper_depth_bound = `upper_depth_bound::value`, 
         lower_depth_bound = `lower_depth_bound::value`) |>
  mutate(across(c(upper_depth_bound, lower_depth_bound), as.numeric)) |>
  mutate(upper_depth_bound = case_when(
    study_id == 'FIA' & str_detect(`depth_bound::method`, '0-4 inch') ~ 0,
    study_id == 'FIA' & str_detect(`depth_bound::method`, '4-8 inch') ~ 4*2.54,
    TRUE ~ upper_depth_bound),
    lower_depth_bound = case_when(
      study_id == 'FIA' & str_detect(`depth_bound::method`, '0-4 inch') ~ 4*2.54,
      study_id == 'FIA' & str_detect(`depth_bound::method`, '4-8 inch') ~ 8*2.54,
      TRUE ~ lower_depth_bound)) |>
  # observation year
  rename(observation_year = `observation_year::value`) |>
  mutate(across(c(observation_year), as.numeric)) |>
  mutate(observation_year = if_else(observation_year < 2300, #does not work for years before 1906
                                    observation_year,
                                    #this is an excel days since origin
                                    lubridate::as_date(observation_year,
                                                       origin = ymd('1900-01-01')) |>
                                      year())) |>
  # bulk density
  rename(bulk_density_fine = `bulk_density_fine::value`, 
         bulk_density_whole = `bulk_density_whole::value`, 
         bulk_density_unknown = `bulk_density_unknown::value`) |>
  mutate(across(c(bulk_density_fine, bulk_density_whole, bulk_density_unknown), as.numeric)) |>
  mutate(`bulk_density_fine::method` = if_else(is.na(bulk_density_fine), 
                                               NA, `bulk_density_fine::method`),
         `bulk_density_whole::method` = if_else(is.na(bulk_density_whole), 
                                               NA, `bulk_density_whole::method`),
         `bulk_density_unknown::method` = if_else(is.na(bulk_density_unknown), 
                                               NA, `bulk_density_unknown::method`)) |>
  mutate(across(c(bulk_density_fine, bulk_density_whole, bulk_density_unknown),
                .fns = function(xx){
                  if_else(xx < 0 | xx > 4, NA, xx)
                })) |>
  # mass fraction values
  rename(total_carbon = `total_carbon::value`,
         organic_carbon = `organic_carbon::value`,
         inorganic_carbon = `inorganic_carbon::value`,
         loss_on_ignition = `loss_on_ignition::value`,
         coarse_fraction = `coarse_fraction::value`) |>
  mutate(across(c(total_carbon, organic_carbon, inorganic_carbon, 
                loss_on_ignition, coarse_fraction), as.numeric)) |>
  mutate(`coarse_fraction::method` = if_else(is.na(coarse_fraction), 
                                             NA, `coarse_fraction::method`),
         `organic_carbon::method` = if_else(is.na(organic_carbon), 
                                            NA, `organic_carbon::method`),
#          `inorganic_carbon::method` = if_else(is.na(inorganic_carbon), 
#                                            NA, `inorganic_carbon::method`),
          `loss_on_ignition::method` = if_else(is.na(loss_on_ignition), 
                                            NA, `loss_on_ignition::method`),
         `total_carbon::method` = if_else(is.na(total_carbon), 
                                          NA, `total_carbon::method`)) |> 
  mutate(across(c(total_carbon, organic_carbon, 
                  inorganic_carbon, loss_on_ignition, coarse_fraction), .fns = function(xx){
    if_else(xx < 0 | xx > 100, NA, xx)
  })) |>
  select(study_id, dataset_id, profile_id, layer_id, 
         country, state,
         latitude, longitude, datum,
         upper_depth_bound, lower_depth_bound, `depth_bound::method`,
         starts_with('observation_year'),
         starts_with('bulk_density'),
         starts_with('total_carbon'),
         starts_with('organic_carbon'),
         starts_with('inorganic_carbon'),
         starts_with('loss_on_ignition'),
         starts_with('coarse_fraction')) |>
  #factor columns <- move to full table later
  mutate(across(study_id, as.factor)) |>
  mutate(across(c(country, state, datum, ends_with('method')), as.factor))

#TODO: Clean this up
ISCN4_meta <- ISCN3_lvl1$meta |>
  bind_rows(FIA_lvl1$meta)

```

## Histograms

```{r fig.width = 8, fig.height = 16}
plot.df <- ISCN4_primary |>
  pivot_longer(cols = where(is.numeric), names_to = 'variable', values_drop_na = TRUE)

ggplot(plot.df) + 
  geom_histogram(aes(x=value), bins = 30) +
  facet_wrap(~study_id + variable, scales = 'free', ncol = 4)
```

## Location over time

```{r fig.width=8, fig.height=10}
ggplot(ISCN4_primary %>%
         select(study_id, dataset_id, profile_id,
                longitude, latitude, observation_year) %>%
         filter(is.finite(longitude + latitude)) %>%
         unique() %>%
         mutate(decade = floor(observation_year/10) * 10)) +
  geom_polygon(colour="grey", fill="white",
               aes(x=long, y=lat, group=group),
               data = map_data("world")) +
  geom_point(aes(x=longitude, y = latitude), alpha = .1) +
  facet_wrap(~decade + study_id, ncol = 4) +
  theme_bw() +
  theme(axis.text = element_blank(),
        axis.title = element_blank())
```

## Depth observations

```{r}
commonBounds <- c(ISCN4_primary$upper_depth_bound, ISCN4_primary$lower_depth_bound) |>
  unique() |>
  sort()

depth_summary <- ISCN4_primary |>
  select(study_id, dataset_id, profile_id,
         upper_depth_bound, lower_depth_bound, organic_carbon) |>
  filter(is.finite(upper_depth_bound + lower_depth_bound)) |>
  unique() |>
  #slice_head(n=200) |>
  reframe(depth = commonBounds[commonBounds >= upper_depth_bound &
                                              commonBounds < lower_depth_bound],
          .by = everything()) |>
  reframe(count = n(),
          organic_carbon_5 = quantile(organic_carbon, probs = 0.05, na.rm =TRUE),
          organic_carbon_25 = quantile(organic_carbon, probs = 0.3, na.rm =TRUE),
          organic_carbon_50 = quantile(organic_carbon, probs = 0.5, na.rm =TRUE),
          organic_carbon_75 = quantile(organic_carbon, probs = 0.75, na.rm =TRUE),
          organic_carbon_95 = quantile(organic_carbon, probs = 0.95, na.rm =TRUE),
          .by = c(depth, study_id))
```

```{r}
ggplot(depth_summary |>
         filter(count > 30)) +
  geom_line(aes(y=count, x = -depth)) +
  coord_flip() +
  facet_wrap(~study_id, scales = 'free')

ggplot(depth_summary |>
         filter(count > 30, depth < 100)) +
  geom_line(aes(y=count, x = -depth)) +
  coord_flip()  +
  facet_wrap(~study_id, scales = 'free_x')
```

```{r}
ggplot(depth_summary |>
         filter(count > 1e3)) +
  geom_ribbon(aes(ymin = organic_carbon_25, 
                  ymax = organic_carbon_75, x = -depth), fill = 'grey') +
  geom_line(aes(y=organic_carbon_5, x = -depth), linetype = 2) +
  geom_line(aes(y=organic_carbon_50, x = -depth)) +
  geom_line(aes(y=organic_carbon_95, x = -depth), linetype = 2) +
  coord_flip() +
  facet_wrap(~study_id, scales = 'free_x')
```

# Appendix

## Read functions

```{r file=file.path(RscriptsDir, databaseReads$ISCN3)}
#| code-summary: "readISCN3"
#| code-fold: true
```

```{r file=file.path(RscriptsDir, databaseReads$FIA)}
#| code-summary: "readFIA"
#| code-fold: true
```

```{r file=file.path(RscriptsDir, databaseReads$NCSS)}
#| code-summary: "readNCSS"
#| code-fold: true
```

